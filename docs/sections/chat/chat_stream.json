[
    { "type": "header", "h": 3, "content": "Chat Stream" },
    {
      "type": "p",
      "content": "This API allows users to interact with the LLM in a streaming mode, where responses are returned as they are generated in real-time."
    },
    { "type": "header", "h": 5, "content": "METHOD: POST" },
    { "type": "snippet", "language": "bash", "content": "/chat/stream" },
    { "type": "header", "h": 3, "content": "Parameters" },
    {
      "type": "table",
      "headers": ["Parameter", "Type", "Required", "Description"],
      "rows": [
        ["user_id", "string", "Yes", "The unique identifier of the user."],
        ["session_id", "string", "Yes", "The unique identifier of the chat session."],
        ["session_title", "string", "No", "Optional session title if creating a new session."],
        ["message", "string", "Yes", "User input message to the LLM."]
      ]
    },
    { "type": "header", "h": 3, "content": "Response Format" },
    {
      "type": "p",
      "content": "Returns a real-time text stream of tokens generated by the LLM in response to the user message."
    },
    { "type": "snippet", "language": "bash", "content": "Hello, how can I assist you today?" },
    {
      "type": "p",
      "content": "The streaming response continues until the full message is generated or the user stops it manually."
    }
  ]
  