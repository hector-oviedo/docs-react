[
  { "type": "header", "h": 3, "content": "Chat Complete" },
  {
    "type": "p",
    "content": "This API allows users to interact with the LLM in a non-streaming mode, where a full response is generated before being returned."
  },
  { "type": "header", "h": 5, "content": "METHOD: POST" },
  { "type": "snippet", "language": "bash", "content": "/chat/complete" },
  { "type": "header", "h": 3, "content": "Parameters" },
  {
    "type": "table",
    "headers": ["Parameter", "Type", "Required", "Description"],
    "rows": [
      ["user_id", "string", "Yes", "The unique identifier of the user."],
      ["session_id", "string", "Yes", "The unique identifier of the chat session."],
      ["session_title", "string", "No", "Optional session title if creating a new session."],
      ["message", "string", "Yes", "User input message to the LLM."]
    ]
  },
  { "type": "header", "h": 3, "content": "Response Format" },
  {
    "type": "p",
    "content": "Returns a JSON object containing the generated response from the LLM."
  },
  { "type": "snippet", "language": "json", "content": "{\n  \"response\": \"Hello, how can I help you?\",\n  \"chat_history\": \"User: Hi!\\nLLM: Hello, how can I help you?\"\n}" },
  {
    "type": "p",
    "content": "The response includes the generated message along with the updated chat history."
  }
]
